

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>AutoSplit &mdash; SophonInference  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="AutoRunner" href="autorunner.html" />
    <link rel="prev" title="SAIL Python API" href="sail_python.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SophonInference
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/abstract.html">Introduction of  Sophon Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/install.html">Sophon Inference Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/reminds.html">Reminds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/tools.html">Useful Tools</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="sail.html">SAIL</a></li>
<li class="toctree-l1"><a class="reference internal" href="sail_cpp.html">SAIL C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="sail_python.html">SAIL Python API</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">AutoSplit</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#graph-infos-json">graph_infos.json</a></li>
<li class="toctree-l2"><a class="reference internal" href="#split">split</a></li>
<li class="toctree-l2"><a class="reference internal" href="#convert">convert</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="autorunner.html">AutoRunner</a></li>
<li class="toctree-l1"><a class="reference internal" href="algokit.html">Algokit</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../demo/release_cpp.html">C++ Samples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo/release_python.html">Python Samples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SophonInference</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>AutoSplit</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/module/autosplit.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="autosplit">
<h1>AutoSplit<a class="headerlink" href="#autosplit" title="Permalink to this headline">¶</a></h1>
<p>AutoSplit only supports FP32 by now.</p>
<p>AutoSplit is a one-click automatical offline model splitting and compiling tool.
For a model that can not be totally deployed on TPU, AutoSplit automatically divide it into several sub-models,
and call the BMCompiler to convert some of the sub-models into bmodel, such as the Fasterrcnn below.</p>
<img alt="../_images/autodeploy.png" src="../_images/autodeploy.png" />
<p>Users don’t need to worry about the splitting and compilation process.
Generated sub-models could be used by the AutoRunner.
The AutoSplit source codes are located in the “module/auto_split/” directory and currently supports tensorflow/mxnet.
We provide two functions in “auto_deploy.api”, which are:</p>
<ul class="simple">
<li>split：</li>
</ul>
<p>Automatically split the model that needs to be deployed into several submodels.
And Save the submodels to the specified directory and save the relevant parameters to the “graph_infos.json” file in the directory.</p>
<ul class="simple">
<li>convert：</li>
</ul>
<p>Parse the “graph_infos.json” file in the specified directory,
and compile all the models in the directory that can be deployed on the TPU into bmodel.</p>
<div class="section" id="graph-infos-json">
<h2>graph_infos.json<a class="headerlink" href="#graph-infos-json" title="Permalink to this headline">¶</a></h2>
<img alt="../_images/split.png" src="../_images/split.png" />
<p>AutoDeploy can automatically split a model into multiple submodels.
So we defined a way to save the submodel after splitting.
The figure above shows the submodels generated by splitting the model of “ssd_mobilenet_v2_coco_2018_03_29” in the tensorflow detection model zoo.
(<a class="reference external" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz">http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz</a>)</p>
<p>“graph_0.pb”, “graph_1.pb”, and “graph_2.pb” in the figure are three submodels generated after splitting,
which are topologically ordered.
That is to say, given the input, the three sub-models are executed sequentially.
The output is consistent with the original unsplitted model.</p>
<p>The “compile_to_graph_ir_1.py” script in the figure compiles “graph_1.pb” into bmodel and saves it in “graph_ir_1/” by calling BMCompiler(bmnett).</p>
<p>The graph_infos.json file contains information about the submodels,
which are:</p>
<ul class="simple">
<li>graphs：</li>
</ul>
<p>A list in which each element contains information of a submodel of “inputs”, “outputs”, “running device (cpu or tpu)”, “model path information (model_info)”.
If the running device is tpu, it will also contain the path where the bmodel is located (context_dir).</p>
<ul class="simple">
<li>tensors：</li>
</ul>
<p>Contains information on the input and output tensors of all submodels.
These tensors are divided into three categories: “input”, “output”, and “intermediate”,
Where “input” and “output” indicate that the tensor is the input and output of the original model,
and “intermediate” indicates that the tensor is the intermediate tensor produced after splitting.</p>
<ul class="simple">
<li>graph_num：</li>
</ul>
<p>Number of submodels after splitting.</p>
<ul class="simple">
<li>platform：</li>
</ul>
<p>The deep learning framework on which the original model is based,
currently supports tensorflow and mxnet.</p>
<ul class="simple">
<li>dynamic：</li>
</ul>
<p>Dynamic mode represents the shape of input tensor of the model is variable.
if it is dynamic, then the size information in tensors is the largest size.</p>
<ul class="simple">
<li>layout：</li>
</ul>
<p>The layout of the original model, NHWC or NCHW.</p>
<p>The following shows the contents of “graph_infos.json” in the figure above:</p>
<blockquote>
<div><div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;graphs&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/div_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/div:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like:0&quot;</span>
       <span class="p">],</span>
      <span class="nt">&quot;model_info&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;model_path&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_0.pb&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;image_tensor:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="nt">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Squeeze:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/convert_scores:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/Reshape_1:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;model_info&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;model_path&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_1.pb&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
      <span class="nt">&quot;context_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_ir_1&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="nt">&quot;outputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;detection_boxes:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;num_detections:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;detection_classes:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;detection_scores:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;model_info&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;model_path&quot;</span><span class="p">:</span> <span class="s2">&quot;graph_2.pb&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Postprocessor/div:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Squeeze:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/convert_scores:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/zeros_like:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/div_1:0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Postprocessor/Reshape_1:0&quot;</span>
      <span class="p">],</span>
      <span class="nt">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="p">}</span>
  <span class="p">],</span>
  <span class="nt">&quot;tensors&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&quot;Postprocessor/div:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Squeeze:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1917</span><span class="p">,</span>
        <span class="mi">4</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/convert_scores:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1917</span><span class="p">,</span>
        <span class="mi">91</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/zeros_like_1:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;num_detections:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/zeros_like:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;detection_classes:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">100</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;detection_boxes:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">100</span><span class="p">,</span>
        <span class="mi">4</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/div_1:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;detection_scores:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">100</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">300</span><span class="p">,</span>
        <span class="mi">300</span><span class="p">,</span>
        <span class="mi">3</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;image_tensor:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">500</span><span class="p">,</span>
        <span class="mi">500</span><span class="p">,</span>
        <span class="mi">3</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;input&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;Postprocessor/Reshape_1:0&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;shape&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mi">1917</span><span class="p">,</span>
        <span class="mi">4</span>
      <span class="p">],</span>
      <span class="nt">&quot;attr&quot;</span><span class="p">:</span> <span class="s2">&quot;intermediate&quot;</span>
    <span class="p">}</span>
  <span class="p">},</span>
  <span class="nt">&quot;graph_num&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
  <span class="nt">&quot;platform&quot;</span><span class="p">:</span> <span class="s2">&quot;tensorflow&quot;</span><span class="p">,</span>
  <span class="nt">&quot;dynamic&quot;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&quot;layout&quot;</span><span class="p">:</span> <span class="s2">&quot;NHWC&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="split">
<h2>split<a class="headerlink" href="#split" title="Permalink to this headline">¶</a></h2>
<p>This function automatically splits the deep learning model that cannot be fully deployed on the TPU into several submodels.
The main function is implemented by the <strong>Splitter</strong> class,
and we defined the process of model splitting in the base class <strong>Splitter</strong>.
Any subclass can call the <strong>convert_and_split</strong> function to complete model splitting,
after implementing a series of virtual functions (such as determining if an op is a supported: is_op_support).
The algorithm for model splitting is shared by each subclass and is implemented in the <strong>auto_deploy.common.graph</strong> module.</p>
<p>Description of <strong>split</strong> function is as follows.
If you want to know the details of the model splitting,
or if you need to implement a new Splitter.
You can refer to the module:
<strong>auto_deploy.common.base_splitter</strong>,  <strong>auto_deploy.common.graph</strong>,  <strong>auto_deploy.splitter</strong>.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@exception_wrapper</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Met an Error when split model.&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span> <span class="n">input_tensors</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">,</span> <span class="n">graph_path</span><span class="p">,</span> \
          <span class="n">params_path</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="s1">&#39;NCHW&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Split the raw model into several submodels.</span>

<span class="sd">  Args:</span>
<span class="sd">    platform: Platform that trained the model.</span>
<span class="sd">              Options: tensorflow, mxnet, pytorch, caffe</span>
<span class="sd">    input_tensors: A dict contains the information of input tensors.</span>
<span class="sd">                  Format: {input_name: numpy.ndarray}</span>
<span class="sd">    save_dir: Path of directory to save submodels and splitting information.</span>
<span class="sd">    graph_path: Path to the graph description file of the model.</span>
<span class="sd">    params_path: Path to the parameters file of the model. Default None.</span>
<span class="sd">    outputs: A list contains the output tensor names. Default None.</span>
<span class="sd">    dynamic: True means input tensor shapes may change. Default False.</span>
<span class="sd">    layout: Layout of tensor. Default &#39;NCHW&#39;.</span>

<span class="sd">  Returns:</span>
<span class="sd">    None.</span>
<span class="sd">  &quot;&quot;&quot;</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="convert">
<h2>convert<a class="headerlink" href="#convert" title="Permalink to this headline">¶</a></h2>
<p>This function compiles the model that can be run on the TPU into the bmodel in the splitted submodels,
based on the device in each graph in the “graph_infos.json” file.
If device is tpu, then the BMCompiler in the corresponding deep learning framework is called to compile the submodel.
The function is implemented by the Compiler class,
and each subclass needs to encapsulate the BMCompiler corresponding to the deep learning framework.</p>
<p>Description of <strong>convert</strong> fucntion is as follows.
For details, refer to modules: <strong>auto_deploy.common.base_compiler</strong> and <strong>auto_deploy.compiler</strong>.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@exception_wrapper</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="s2">&quot;Met an Error when compile model.&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">convert</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">compare</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;BM1682&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Compile all the subgraphs which can deploy on sophon.</span>

<span class="sd">  Args:</span>
<span class="sd">    folder: path that contains splitted models,</span>
<span class="sd">            &#39;graph_infos.json&#39; must be under this folder</span>

<span class="sd">    Format of &#39;graph_infos.json&#39;:</span>
<span class="sd">    {</span>
<span class="sd">      &quot;graph_num&quot;: graph_numbmer,</span>
<span class="sd">      &quot;platform&quot;: &quot;mxnet&quot;</span>
<span class="sd">      &quot;layout&quot;: &quot;NCHW&quot;</span>
<span class="sd">      &quot;dynamic&quot;: False</span>
<span class="sd">      &quot;graphs&quot;: [</span>
<span class="sd">        {</span>
<span class="sd">          &quot;device&quot;: &quot;cpu&quot;,</span>
<span class="sd">          &quot;inputs&quot;: list of input tensor names,</span>
<span class="sd">          &quot;outputs&quot;: list of output tensor names,</span>
<span class="sd">          &quot;model_info&quot;: {</span>
<span class="sd">            &quot;json&quot;: json_file_path,</span>
<span class="sd">            &quot;params&quot;: params_file_path</span>
<span class="sd">          }</span>
<span class="sd">        }</span>
<span class="sd">      ]</span>
<span class="sd">      &quot;tensors&quot;: [</span>
<span class="sd">        {</span>
<span class="sd">          &quot;name&quot;: name,</span>
<span class="sd">          &quot;shape&quot;: list for shape,</span>
<span class="sd">          &quot;attr&quot;: &quot;input&quot; or &quot;output&quot; or &quot;intermediate&quot;</span>
<span class="sd">        }</span>
<span class="sd">      ]</span>
<span class="sd">    }</span>
<span class="sd">    optimize: optimizing mode, parameter of bmnet compiler.</span>
<span class="sd">    compare: if compare with cpu results when compiling.</span>
<span class="sd">    target: &#39;BM1682&#39; or &#39;BM1684&#39;(future).</span>

<span class="sd">  Returns: None.</span>
<span class="sd">  &quot;&quot;&quot;</span>
</pre></div>
</div>
</div></blockquote>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="autorunner.html" class="btn btn-neutral float-right" title="AutoRunner" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="sail_python.html" class="btn btn-neutral float-left" title="SAIL Python API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Sophon

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>