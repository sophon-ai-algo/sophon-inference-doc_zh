SAIL C++ API
============

Basic function
_____

**1). get_available_tpu_num**
    .. code-block:: c++

        @brief Get the number of available TPUs.

        @return Number of available TPUs.

        int get_available_tpu_num();

Data type
_____

**1). bm_data_type_t**
    .. code-block:: c++

        enum bm_data_type_t {
          BM_FLOAT32,     // float32
          BM_FLOAT16,     // not supported for now
          BM_INT8,        // int8
          BM_UINT8        // unsigned int8
        };

Handle
_____

**1). Handle Constructor**
    .. code-block:: c++

        @brief Constructor using existed bm_handle_t.

        @param handle A bm_handle_t

        Handle(bm_handle_t handle);

**2). Handle Constructor**
    .. code-block:: c++

        @brief Constructor with device id.

        @param dev_id Device id

        Handle(int dev_id);

**3). data**
    .. code-block:: c++

        @brief Get inner bm_handle_t.

        @return Inner bm_handle_t

        bm_handle_t data();

**4). free**
    .. code-block:: c++

        @brief Free inner bm_handle_t.

        void free();

Tensor
_____

**1). Tensor Constructor**
    .. code-block:: c++

        @brief Common constructor.
        @detail
         case 0: only allocate system memory
                 (handle, shape, dtype, true, false)
         case 1: only allocate device memory
                 (handle, shape, dtype, false, true)
         case 2: allocate system memory and device memory
                 (handle, shape, dtype, true, true)

        @param handle       Handle instance
        @param shape        Shape of the tensor
        @param own_sys_data Indicator of whether own system memory.
        @param own_dev_data Indicator of whether own device memory.

        explicit Tensor(
            Handle                  handle,
            const std::vector<int>& shape,
            bm_data_type_t          dtype,
            bool                    own_sys_data,
            bool                    own_dev_data);

**2). Tensor Copy Constructor**
    .. code-block:: c++

        @brief Copy constructor.

        @param tensor A Tensor instance

        Tensor(const Tensor& tensor);

**3). Tensor Assign Function**
    .. code-block:: c++

        @brief Assignment function.

        @param tensor A Tensor instance
        @return A Tensor instance

        Tensor& operator=(const Tensor& tensor);

**4). shape**
    .. code-block:: c++

        @brief Get shape of the tensor.

        @return Shape of the tensor

        const std::vector<int>& shape() const;

**5). dtype**
    .. code-block:: c++

        @brief Get data type of the tensor.

        @return Data type of the tensor

        void dtype();

**6). reshape**
    .. code-block:: c++

        @brief Reset shape of the tensor.

        @param shape Shape of the tensor

        void reshape(const std::vector<int>& shape);

**7). own_sys_data**
    .. code-block:: c++

        @brief Judge if the tensor owns data in system memory.

        @return True for owns data in system memory.

        bool own_sys_data();

**8). own_dev_data**
    .. code-block:: c++

        @brief Judge if the tensor owns data in device memory.

        @return True for owns data in device memory.

        bool own_dev_data();

**9). sys_data**
    .. code-block:: c++

        @brief Get data pointer in system memory of the tensor.

        @return Data pointer in system memory of the tensor

        void* sys_data();

**10). dev_data**
    .. code-block:: c++

        @brief Get pointer to device memory of the tensor.

        @return Pointer to device memory of the tensor

        bm_device_mem_t* dev_data();

**11). reset_sys_data**
    .. code-block:: c++

        @brief Reset data pointer in system memory of the tensor.

        @param data  Data pointer in system memory of the tensor
        @param shape Shape of the data

        void reset_sys_data(
            viod*              data,
            std::vector<int>& shape);

**12). reset_dev_data**
    .. code-block:: c++

        @brief Reset pointer to device memory of the tensor.

        @param data Pointer to device memory

        void reset_dev_data(bm_device_mem_t* data);

**13). sync_s2d**
    .. code-block:: c++

         @brief Copy data from system memory to device memory.

         void sync_s2d();

**14). sync_s2d**
    .. code-block:: c++

        @brief Copy data from system memory to device memory with specified size.

        @param size Byte size to be copied

        void sync_s2d(int size);

**15). sync_d2s**
    .. code-block:: c++

         @brief Copy data from device memory to system memory.

         void sync_d2s();

**16). sync_d2s**
    .. code-block:: c++

        @brief Copy data from device memory to system memory with specified size.

        @param size Byte size to be copied

        void sync_d2s(int size);

**17). free**
    .. code-block:: c++

       @brief Free system and device memroy of the tensor.

       void free();

IOMode
______

**1). IOMode**
    .. code-block:: c++

        enum IOMode {
          /// Input tensors are in system memory while output tensors are
          /// in device memory.
          SYSI,
          /// Input tensors are in device memory while output tensors are
          /// in system memory.
          SYSO,
          /// Both input and output tensors are in system memory.
          SYSIO,
          /// Both input and output tensors are in device memory.
          DEVIO
        };

Engine
______

**1). Engine Constructor**
    .. code-block:: c++

        @brief Constructor does not load bmodel.

        @param tpu_id TPU ID. You can use bm-smi to see available IDs.

        Engine(int tpu_id);

**2). Engine Constructor**
    .. code-block:: c++

        @brief Constructor loads bmodel from file.

        @param bmodel_path Path to bmodel
        @param tpu_id      TPU ID. You can use bm-smi to see available IDs.
        @param mode        Specify the input/output tensors are in system memory
                           or device memory
        Engine(
            const std::string& bmodel_path,
            int                tpu_id,
            IOMode             mode);

**3). Engine Constructor**
    .. code-block:: c++

        @brief Constructor loads bmodel from system memory.

        @param bmodel_ptr  Pointer to bmodel in system memory
        @param bmodel_size Byte size of bmodel in system memory
        @param tpu_id      TPU ID. You can use bm-smi to see available IDs.
        @param mode        Specify the input/output tensors are in system memory
                           or device memory

        Engine(
            const void* bmodel_ptr,
            size_t      bmodel_size,
            int         tpu_id,
            IOMode      mode);

**4). Engine Copy Constructor**
    .. code-block:: c++

        @brief Copy constructor.

        @param other An other Engine instance.

        Engine(const Engine& other);

**5). Engine Assign Function**
    .. code-block:: c++

        @brief Assignment function.

        @param other An other Engine instance.
        @return Reference of a Engine instance.

        Engine<Dtype>& operator=(const Engine& other);

**6). get_handle**
    .. code-block:: c++

        @brief Get Handle instance.

        @return Handle instance

        Handle get_handle();

**7). load**
    .. code-block:: c++

        @brief Load bmodel from file.

        @param bmodel_path Path to bmodel
        @return Program state
            @retval true  Success
            @retval false Failure

        bool load(const std::string& bmodel_path);

**8). load**
    .. code-block:: c++

        @brief Load bmodel from system memory.

        @param bmodel_ptr  Pointer to bmodel in system memory
        @param bmodel_size Byte size of bmodel in system memory
        @return Program state
            @retval true  Success
            @retval false Failure

        bool load(const void* bmodel_ptr, size_t bmodel_size);

**9). get_graph_names**
    .. code-block:: c++

        @brief Get all graph names in the loaded bomodels.

        @return All graph names

        std::vector<std::string> get_graph_names();

**10). graph_is_dynamic**
    .. code-block:: c++

        @brief Jugde if the graph is dynamic.

        @param graph_name The specified graph name
        @return 0 for dynamic and 1 for static

        bool graph_is_dynamic(const std::string& graph_name);

**11). get_input_names**
    .. code-block:: c++

        @brief Get all input tensor names of the specified graph.

        @param graph_name The specified graph name
        @return All the input tensor names of the graph

        std::vector<std::string> get_input_names(const std::string& graph_name);

**12). get_output_names**
    .. code-block:: c++

        @brief Get all output tensor names of the specified graph.

        @param graph_name The specified graph name
        @return All the output tensor names of the graph

        std::vector<std::string> get_output_names(const std::string& graph_name);

**13). get_max_input_shapes**
    .. code-block:: c++

        @brief Get max shapes of input tensors in a graph.

        For static models, the max shape is fixed and it should not be changed.
        For dynamic models, the tensor shape should be smaller than or equal to
        the max shape.

        @param graph_name The specified graph name
        @return Max shape of input tensors

        std::map<std::string, std::vector<int>> get_max_input_shapes(
            const std::string& graph_name);

**14). get_input_shape**
    .. code-block:: c++

        @brief Get the shape of an input tensor in a graph.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return The shape of the tensor

        std::vector<int> get_input_shape(
            const std::string& graph_name,
            const std::string& tensor_name);

**15). get_max_output_shapes**
    .. code-block:: c++

        @brief Get max shapes of output tensors in a graph.

        For static models, the max shape is fixed and it should not be changed.
        For dynamic models, the tensor shape should be smaller than or equal to
        the max shape.

        @param graph_name The specified graph name
        @return Max shape of output tensors

        std::map<std::string, std::vector<int>> get_max_output_shapes(
            const std::string& graph_name);

**16). get_output_shape**
    .. code-block:: c++

        @brief Get the shape of an output tensor in a graph.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return The shape of the tensor

        std::vector<int> get_output_shape(
            const std::string& graph_name,
            const std::string& tensor_name);

**17). get_input_dtype**
    .. code-block:: c++

        @brief Get data type of an input tensor. Refer to bmdef.h as following.
          typedef enum {
            BM_FLOAT32 = 0,
            BM_FLOAT16 = 1,
            BM_INT8 = 2,
            BM_UINT8 = 3,
            BM_INT16 = 4,
            BM_UINT16 = 5,
            BM_INT32 = 6,
            BM_UINT32 = 7
          } bm_data_type_t;

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return Data type of the input tensor

        bm_data_type_t get_input_dtype(
            const std::string& graph_name,
            const std::string& tensor_name);

**18). get_output_dtype**
    .. code-block:: c++

        @brief Get data type of an output tensor. Refer to bmdef.h as following.
          typedef enum {
            BM_FLOAT32 = 0,
            BM_FLOAT16 = 1,
            BM_INT8 = 2,
            BM_UINT8 = 3,
            BM_INT16 = 4,
            BM_UINT16 = 5,
            BM_INT32 = 6,
            BM_UINT32 = 7
          } bm_data_type_t;

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return Data type of the input tensor

        bm_data_type_t get_output_dtype(
            const std::string& graph_name,
            const std::string& tensor_name);

**19). get_input_scale**
    .. code-block:: c++

        @brief Get scale of an input tensor. Only used for int8 models.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return Scale of the input tensor

        float get_input_scale(
            const std::string& graph_name,
            const std::string& tensor_name);

**20). get_output_scale**
    .. code-block:: c++

        @brief Get scale of an output tensor. Only used for int8 models.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return Scale of the output tensor

        float get_output_scale(
            const std::string& graph_name,
            const std::string& tensor_name);

**21). reshape**
    .. code-block:: c++

        @brief Reshape input tensor for dynamic models.

        The input tensor shapes may change when running dynamic models.
        New input shapes should be set before inference.

        @param graph_name   The specified graph name
        @param input_shapes Specified shapes of all input tensors of the graph
        @return 0 for success and 1 for failure

        int reshape(
            const std::string&                       graph_name,
            std::map<std::string, std::vector<int>>& input_shapes);

**22). get_input_tensor**
    .. code-block:: c++

        @brief Get the specified input tensor.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return The specified input tensor

        Tensor* get_input_tensor(
            const std::string& graph_name,
            const std::string& tensor_name);

**23). get_output_tensor**
    .. code-block:: c++

        @brief Get the specified output tensor.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @return The specified output tensor

        Tensor* get_output_tensor(
            const std::string& graph_name,
            const std::string& tensor_name);

**24). scale_input_tensor**
    .. code-block:: c++

        @brief Scale input tensor for int8 models.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @param data        Pointer to float data to be scaled

        void scale_input_tensor(
            const std::string& graph_name,
            const std::string& tensor_name,
            float*             data);

**25). scale_output_tensor**
    .. code-block:: c++

        @brief Scale output tensor for int8 models.

        @param graph_name  The specified graph name
        @param tensor_name The specified tensor name
        @param data        Pointer to float data to be scaled

        void scale_output_tensor(
            const std::string& graph_name,
            const std::string& tensor_name,
            float*             data);


**26). scale_fp32_to_int8**
    .. code-block:: c++

        @brief Scale data from float32 to int8. Only used for int8 models.

        @param src   Poniter to float32 data
        @param dst   Poniter to int8 data
        @param scale Value of scale
        @param size  Size of data

        void scale_fp32_to_int8(float* src, int8_t* dst, float scale, int size);

**27). scale_fp32_to_int8**
    .. code-block:: c++

        @brief Scale data from int8 to float32. Only used for int8 models.

        @param src   Poniter to int8 data
        @param dst   Poniter to float32 data
        @param scale Value of scale
        @param size  Size of data

        void scale_int8_to_fp32(int8_t* src, float* dst, float scale, int size);

**28). process**
    .. code-block:: c++

        @brief Inference with builtin input and output tensors.

        @param graph_name The specified graph name

        void process(const std::string& graph_name);

**29). process**
    .. code-block:: c++

        @brief Inference with provided input tensors.

        @param graph_name    The specified graph name
        @param input_shapes  Shapes of all input tensors
        @param input_tensors Data pointers of all input tensors in system meory
        @param scale         Indicator of multiply scale for input tensors or not

        void process(
            const std::string&                       graph_name,
            std::map<std::string, std::vector<int>>& input_shapes,
            std::map<std::string, void*>&            input_tensors);

**30). process**
    .. code-block:: c++

        @brief Inference with provided input and output tensors.

        @input Input tensors
        @output Output tensors

        void process(
            const std::string&              graph_name,
            std::map<std::string, Tensor*>& input,
            std::map<std::string, Tensor*>& output);
