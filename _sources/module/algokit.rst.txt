Algokit
=======

**Algokit** is a python module for sophon-inference application-oriented deployments that currently provides examples of computer vision applications such as image classification, detection, and segmentation.
**Algokit** relies on the model deployment related interfaces provided by SAIL and AutoRunner.

Introduction
____________

Each application in **Algokit** is an instance of a subclass of algokit.engine.base_engine.BaseEngine.
The subclasses are implemented under algokit.algo_cv, algokit.algo_nlp and algokit.algo_speech.
By now, we have some computer vision applications under algokit.algo_cv.
algo_nlp and algo_speech are still in development.

Current application list is as follows:

* Image classification using caffe model

algokit.algo_cv.cls.general_classification.GeneralClassification

* Image classification using mxnet model

algokit.algo_cv.cls.general_classification_mx.GeneralClassificationMX

* Image classification using pytorch model

algokit.algo_cv.cls.general_classification_pt.GeneralClassificationPT

* Image classification using tensorflow model

algokit.algo_cv.cls.general_classification_tf.GeneralClassificationTF

* Object detection of fasterrcnn_vgg16 using caffe model

algokit.algo_cv.det.object_detection_fasterrcnn.ObjectDetectionFASTERRCNN

* Object detection of fasterrcnn_resnet50 using tensorflow model

algokit.algo_cv.det.object_detection_fasterrcnn_resnet50_tf.ObjectDetectionFASTERRCNNRESNET50TF

* Object detection of mobilenetssd using caffe model

algokit.algo_cv.det.object_detection_mobilenetssd.ObjectDetectionMOBILENETSSD

* Object detection of mobilenetyolov3 using caffe model

algokit.algo_cv.det.object_detection_mobilenetyolov3.ObjectDetectionMOBILENETYOLOV3

* Object detection of yolov3 using caffe model

algokit.algo_cv.det.object_detection_yolov3.ObjectDetectionYOLOV3

* Object detection of yolov3 using mxnet model

algokit.algo_cv.det.object_detection_yolov3_mx.ObjectDetectionYOLOV3MX

* Face detection of mtcnn using caffe model

algokit.algo_cv.det.face_detection_mtcnn.FaceDetectionMTCNN

* Face detection of ssh using caffe model

algokit.algo_cv.det.face_detection_ssh.FaceDetectionSSH

* Segementation of mobilenetv2_deeplabv3 using tensorflow model

algokit.algo_cv.seg.semantic_segmentation_deeplabv3_mobilenetv2_tf.SemanticSegmentationDEEPLABV3MOBILENETV2TF


We use factories to create aplication based on their categories and dependencies.
While the factories are all under algokit.algofactory module.
Current include:

* General Image classification

algokit.algofactory.generalclassification_factory.GeneralClassifier

* Object detection

algokit.algofactory.objectdetection_factory.ObjectDetector

* Face Detection

algokit.algofactory.facedetection_factory.FaceDetector

* Applications using auto_deploy

algokit.algofactory.autodeploy_factory.ObjectDetector

algokit.algofactory.autodeploy_factory.SemanticSegment


For SAIL, **Algokit** implements its own engine, which encapsulates SAIL's engine class and implements bmodel loading and running.
"generalclassification_factory", "objectdetection_factory" and "facedetection_factory" are all based on engine module to drive TPU for reasoning.
For AutoDeploy, **Algokit** encapsulates its split, convert, and infer functions, and implements the "autodeploy_factory" module after encapsulation.

Add an application(e.g. mobilenetssd)
_____________________________________


**1). Creates a new class for the specified algorithm**

    .. code-block:: python

       # MobilenetSSD belong to CV detection algorithm
       # Create the new class in algokit/algo_cv/det
       # The parent class BaseEngine contains some basic data processing operations
       class ObjectDetectionMOBILENETSSD(BaseEngine):
       """Construct mobilenetssd detector
       """
       def __init__(self, param1, param2, ...):
         super(ObjectDetectionMOBILENETSSD, self).__init__()
         self.xxx = xxx # member variable init
         self.net = Engine(model_description_dict, chip_mode) # Construct TPU inference engine
       def mobilenetssd_postprocess(self, ...):
         """
         processing after inference e.g. detection output layer
         """
         pass
       def mobilenetssd_preporcess(self, ...):
         """
         different frameworks and types of algorithm preprocess are different
         or call the base operation of the parent class
         """
         pass
       def xxx(self, ...):
         """
         additional operation
         """
         pass

**2). Add corresponding branch in the algorithm factory**

    .. code-block:: python

       # Add the new branch in algokit/algofactory/objectdetection_factory
       # 1. Add branch in create method
       if detection_model is ObjDetModel.MOBILENETSSD:
       from ..algo_cv.det.object_detection_mobilenetssd import \
         import ObjectDetecitonMOBILENETSSD as Detector

       # 2. Add global DEFAULT_XXX_PARAM
       DEFAULT_MOBILENETSSD_PARAM = {
           'detected_size': (300, 300),
           'threshold': 0.25,
           'nms_threshold': 0.45,
           'num_classes': 21,
           'priorbox_num': 1917
       }
       # 3. Add param loader branch in load_param method
       if default_param is ObjDetModel.MOBILENETSSD:
         default_param = DEFAULT_MOBILENETSSD_PARAM

**3). Add a new algorithm type in algokit global config**

    .. code-block:: python

       # Add the new algorithm type in algokit/kitconfig
       class ObjDetModel(Enum):
         """The object detection algorithm model
         """
         ...
         ...
         MOBILENETSSD = 'mobilenetssd'

**4). Add a new model description config file**

    .. code-block:: python

       # Add the new model description config file in algokit/engine/engineconfig
       # Create new json file: bm1682_mobilenetssd.json
       {
         "arch": {
           "context_path": "mobilenetssd_ir/compilation.bmodel", # bmodel path suffixï¼Œbase path: ${HOME}/.sophon/models
           "is_dynamic": false, # the inputs size of model is variable
           "tpus": "0", # tpu id
           "input_names": ["data"], # the input names of model
           "output_names": ["mbox_conf_flatten", "mbox_loc", "mbox_priorbox"], # the output names of model
           "input_shapes": [[1, 3, 300, 300]] # the default input size of model
         }
       }

